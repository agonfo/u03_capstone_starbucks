{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in case remember you have to upgrade scikit-learn .. see README\n",
    "# !pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import KBinsDiscretizer , StandardScaler\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline , Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data ():\n",
    "    '''\n",
    "    load data\n",
    "    IMPUT:\n",
    "    OUTPUT: type_1 , type_2 , type_3 , type_4 (dataFrame) processed data from 02_data pre-processing\n",
    "    '''  \n",
    "    # read in the csv files\n",
    "    type_1 = pd.read_csv('data/amount_type_1.csv').drop(columns = 'user id')\n",
    "    type_2 = pd.read_csv('data/amount_type_2.csv').drop(columns = 'user id')\n",
    "    type_3 = pd.read_csv('data/amount_type_3.csv').drop(columns = 'user id')\n",
    "    type_4 = pd.read_csv('data/amount_type_4.csv').drop(columns = 'user id')\n",
    "\n",
    "    return type_1 , type_2 , type_3 , type_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clear outsiders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_outsiders (df , col , max_offer):\n",
    "    '''\n",
    "    drop outsiders\n",
    "    IMPUT:\n",
    "        df (dataFrame) - data to be modify\n",
    "        col (str) - name of the column that has NaN values to clear\n",
    "        max_offer (int) -   maximum value spected in a transaction influenced by an offer \n",
    "                            (e.g. someone that spend more than 1000$ it's unlikely that was influenced by an offer)\n",
    "    OUTPUT:\n",
    "        df (dataFrame) without outsiders\n",
    "    '''  \n",
    "    #remove values > max_offer \n",
    "    df = df.drop(df[df[col] > max_offer ].index)\n",
    "    \n",
    "    #round values\n",
    "    df[col] = (df[col] * 10).round(0)\n",
    "    df = df.astype(int)\n",
    "    \n",
    "    #removing value 0\n",
    "    df = df.drop(df[df[col] == 0 ].index)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketizer(df , col, bins=10):\n",
    "    '''\n",
    "    Create buckets for a given column\n",
    "    IMPUT:\n",
    "        df (dataFrame) - data to be modify\n",
    "        col (str) - name of the column to be bucketize\n",
    "        bins (int) - number of bins to be created\n",
    "    OUTPUT:\n",
    "        values_pp (Series) Serie of the bucketize column\n",
    "    '''\n",
    "    values_np = df[col].values.reshape(-1,1)\n",
    "    bucketizer =  KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='uniform').fit(values_np)\n",
    "    values_pp = bucketizer.transform(values_np)\n",
    "    \n",
    "    return values_pp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df , lable):\n",
    "    '''\n",
    "    split data set into Train and Test\n",
    "    IMPUT:\n",
    "        df (dataFrame)\n",
    "        lable (str) - name of the label to be predicted\n",
    "    OUTPUT:\n",
    "        X_train, X_test  (dataFrame) split data Train - Test\n",
    "        y_train_box, y_test (Series) split data Train - Test\n",
    "    '''\n",
    "    \n",
    "    X = df.drop(columns = [lable])\n",
    "    y = df[lable]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , random_state=42)\n",
    "         \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def log_box_cox (y_train):\n",
    "    '''\n",
    "    Apply log (box-cox) to the y_Train to have a normal distribution of the data\n",
    "    IMPUT: y_train (Series)\n",
    "    OUTPUT:\n",
    "        y_train_box (Series) data after log\n",
    "        maxlog - (int) value of the lmbda parameter to reverse the applied log\n",
    "    '''\n",
    "    box_train , maxlog = stats.boxcox(y_train)\n",
    "    y_train_box = pd.Series(box_train)\n",
    "\n",
    "    return y_train_box , maxlog\n",
    "\n",
    "\n",
    "def train_model (X_train , y_train):\n",
    "    '''\n",
    "    train model\n",
    "    IMPUT:\n",
    "        X_train (dataFrame)\n",
    "        y_train (series)\n",
    "    OUTPUT:\n",
    "        clf (Pipeline) fit model pipeline\n",
    "    '''       \n",
    "    clf = make_pipeline(StandardScaler() , SVR())\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "def grid (clf , X_train , y_train):\n",
    "    '''\n",
    "    apply GridSearchCV to the pipeline to get best parameters\n",
    "    IMPUT:\n",
    "        clf (Pipeline) fit model pipeline\n",
    "        X_train (dataFrame)\n",
    "        y_train (series)\n",
    "    OUTPUT:\n",
    "        grid (Pipeline) fit model pipeline with best parameters\n",
    "    ''' \n",
    "    \n",
    "    parameters = {\n",
    "        'svr__kernel': ('linear', 'poly' , 'rbf'),\n",
    "        'svr__C' : (0.5 , 0.75 , 1.0),\n",
    "        'svr__shrinking' : (True , False),\n",
    "        'svr__gamma': ('scale','auto')\n",
    "    }\n",
    "    \n",
    "    grid = GridSearchCV(clf, param_grid=parameters)\n",
    "    grid.fit(X_train,y_train)\n",
    "    print(\"\\nBest Parameters:\", grid.best_params_)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def predict (clf , X_test , maxlog , log=True):\n",
    "    '''\n",
    "    predict values\n",
    "    IMPUT:\n",
    "        clf (Pipeline)\n",
    "        X_test (dataFrame)\n",
    "        maxlog (int) - value of the lmbda parameter to reverse the applied log\n",
    "        log - (boolean) if true apply log (box-cox)\n",
    "        \n",
    "    OUTPUT: \n",
    "        y_pred (array) test prediction \n",
    "    '''\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "    if log:\n",
    "        y_pred = inv_boxcox(predictions, maxlog)\n",
    "        y_pred = np.nan_to_num(y_pred)  # in some cases inv_boxcox can return a NaN (when is a complex number)\n",
    "    else:\n",
    "        y_pred = predictions\n",
    "   \n",
    "    return y_pred\n",
    "\n",
    "def build_model (df , lable , max_offer, log=True , bucket=True , outsiders=True):\n",
    "    '''\n",
    "    create and train the model\n",
    "    IMPUT:\n",
    "        df (dataFrame) data set of for a type of offer\n",
    "        lable (str) - name of the label to be predicted\n",
    "        max_offer (int)\n",
    "        *** the purpose of the following booleans is to create visual graph to represent the evolution of the model\n",
    "        log - (boolean) if true apply log (box-cox) \n",
    "        bucket - (boolean) if true apply bucketizer\n",
    "        outsiders - (boolean) if true apply clear_outsiders\n",
    "        \n",
    "    OUTPUT:\n",
    "        X_train, X_test  (dataFrame) \n",
    "        y_train , y_test (Series)\n",
    "        y_pred (array) test prediction \n",
    "        lable (str) - name of the label to be predicted\n",
    "        max_offer (int)\n",
    "        model (Pipelane)\n",
    "        maxlog (int) - value of the lmbda parameter to reverse the applied log\n",
    "    '''\n",
    "\n",
    "    #clear outsiders\n",
    "    if outsiders:\n",
    "        df = clear_outsiders (df , lable ,  max_offer)\n",
    "    \n",
    "    #bucketizer\n",
    "    if bucket:\n",
    "        df['age'] = bucketizer(df , 'age' , 8)\n",
    "        df['income'] = bucketizer(df , 'income' , 9)\n",
    "    \n",
    "    #split into train and test\n",
    "    X_train, X_test, y_train, y_test = split_data (df , lable)\n",
    "\n",
    "    if log:\n",
    "        y_train , maxlog = log_box_cox (y_train)\n",
    "    else:\n",
    "        maxlog = 0\n",
    "\n",
    "    clf = train_model (X_train , y_train)\n",
    "    grid_pipeline = grid(clf, X_train , y_train)\n",
    "    model = grid_pipeline.best_estimator_\n",
    "\n",
    "\n",
    "    y_pred = predict (model , X_test , maxlog , log )\n",
    "    \n",
    "    return X_train , X_test , y_train , y_test , y_pred , lable , max_offer , model , maxlog\n",
    "\n",
    "\n",
    "def print_results(y_train , y_test , y_pred , lable , max_offer):\n",
    "    '''\n",
    "    print results\n",
    "    IMPUT:\n",
    "        y_train , y_test (Series)\n",
    "        y_pred (array) test prediction \n",
    "        lable (str) - name of the label to be predicted\n",
    "        max_offer (int)\n",
    "        \n",
    "    OUTPUT:  \n",
    "    '''\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print ('r2 score =' , r2)\n",
    "\n",
    "    mu = y_train.mean()  # mean of distribution\n",
    "    sigma = np.std(y_train)  # standard deviation of distribution\n",
    "    \n",
    "    num_bins = 100\n",
    "    f1, ax1 = plt.subplots()\n",
    "\n",
    "    n, bins, patches = ax1.hist(y_train, num_bins, density=1)\n",
    "\n",
    "    # add a 'best fit' line\n",
    "    y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "         np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "    ax1.plot(bins, y, '--')\n",
    "    ax1.set_xlabel('amount transaction ($) - label data')\n",
    "    ax1.set_ylabel('Number of users')\n",
    "    ax1.set_title('data to be trained - checking if its a normal distribution')\n",
    "\n",
    "    # Tweak spacing to prevent clipping of ylabel\n",
    "    f1.tight_layout()\n",
    "    plt.show();        \n",
    "       \n",
    "    f2, ax2 = plt.subplots()\n",
    "    ax2.plot(range(max_offer * 10))\n",
    "    f2.suptitle(lable, fontsize=15)\n",
    "    plt.xlabel('train values')\n",
    "    plt.ylabel('prediction values')\n",
    "    ax2.scatter(y_test.values , y_pred , s=10 , c='r')\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "type_1 , type_2 , type_3 , type_4 = load_data ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to have same name for each data set\n",
    "type_1.rename(columns={'offers type 1': 'offers', 'viewed type 1': 'viewed' , 'completed type 1' : 'completed'} , inplace=True)\n",
    "type_2.rename(columns={'offers type 2': 'offers', 'viewed type 2': 'viewed' , 'completed type 2' : 'completed'} , inplace=True)\n",
    "type_3.rename(columns={'offers type 3': 'offers', 'viewed type 3': 'viewed' , 'completed type 3' : 'completed'} , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type 1 bogo\n",
    "X_train_1 , X_test_1 , y_train_1 , y_test_1 , y_pred_1 , lable_1 , max_offer_1 , bogo_model , bogo_maxlog = build_model(type_1 , 'type 1' , 40)\n",
    "print_results (y_train_1 , y_test_1 , y_pred_1 , lable_1 , max_offer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type 2 Informational\n",
    "X_train_2 , X_test_2 , y_train_2 , y_test_2 , y_pred_2 , lable_2 , max_offer_2 , info_model , info_maxlog = build_model(type_2 , 'type 2' , 40)\n",
    "print_results (y_train_2 , y_test_2 , y_pred_2 , lable_2 , max_offer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type 3 Discount\n",
    "X_train_3 , X_test_3 , y_train_3 , y_test_3 , y_pred_3 , lable_3 , max_offer_3 , disc_model , disc_maxlog = build_model(type_3 , 'type 3' , 40)\n",
    "print_results (y_train_3 , y_test_3 , y_pred_3 , lable_3 , max_offer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type 4 No offer\n",
    "X_train_4 , X_test_4 , y_train_4 , y_test_4 , y_pred_4 , lable_4 , max_offer_4 , no_offer_model , no_offer_maxlog = build_model(type_4 , 'type 4' , 40)\n",
    "print_results (y_train_4 , y_test_4 , y_pred_4 , lable_4 , max_offer_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking max offer value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_max_offer(df , label , range_test):\n",
    "\n",
    "    r2_lst = []\n",
    "\n",
    "    for max_offer in range_test:\n",
    "        X_train , X_test , y_train , y_test , y_pred , lable , max_offer , model , maxlog = build_model(df , label , max_offer)\n",
    "        r2_lst.append(r2_score(y_test, y_pred))\n",
    "\n",
    "    f3, ax3 = plt.subplots()\n",
    "    ax3.plot(range_test, r2_lst)\n",
    "    ax3.plot(np.linspace(40,40,5) , np.linspace(0,0.8,5))\n",
    "\n",
    "    ax3.set(xlabel='max offer ($)', ylabel='r2 error',\n",
    "        title='max offer for a better r2 model result')\n",
    "    ax3.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_test = range(10 , 500 , 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_max_offer(type_1 , 'type 1' , range_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv')",
   "language": "python",
   "name": "python37764bitvenvf7323f51036b43e7a745900362034ad3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}