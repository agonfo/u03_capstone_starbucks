{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_mapper(df , column):\n",
    "    '''\n",
    "    Map a column in a DataFrame and create a dict to change its value to a sequence (1,2,3...) for easier use. \n",
    "        \n",
    "    INPUT:\n",
    "        df - (DataFrame) \n",
    "        column - (str) name of the column to create dictionary\n",
    "    OUTPUT:\n",
    "        coded_dict - (dict) A dictionary with the given column values as key and the 'new' encoded sequence as value\n",
    "    '''  \n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    \n",
    "    for x in df[column]:\n",
    "        if x not in coded_dict:\n",
    "            coded_dict[x] = cter\n",
    "            cter+=1\n",
    "            \n",
    "    return coded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offer_type_mapper(df=portfolio):\n",
    "    '''\n",
    "   Create a data frame to relate each offer with offer type\n",
    "    \n",
    "    IMPUT:  df - (DataFrame) - portfolio as default dataframe \n",
    "    OUTPUT: \n",
    "            offer_type - (DataFrame) - relation between offer id and type of offer  \n",
    "            coded_dict - (dict) - relation between type offer sequence and real type offer (see id_mapper)\n",
    "    \n",
    "    '''    \n",
    "    # get sequence to name type of offers\n",
    "    coded_dict = id_mapper(df, 'offer_type')\n",
    "    \n",
    "    coded_df = df.replace({\"offer_type\":coded_dict})\n",
    "    offer_type = coded_df[['id' , 'offer_type' , 'duration']]\n",
    "    \n",
    "    return offer_type , coded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_events(df , offer_df):\n",
    "    '''\n",
    "    Rearange the dataframe -transcript- by merging each offer into one row, creating columns for each event and time as values.\n",
    "    \n",
    "    IMPUT: df (DataFrame) - default Dataframe is transcript\n",
    "    OUTPUT: df (DataFrame) - modified dataFrame\n",
    "    '''\n",
    "    \n",
    "    # read dictionary from 'value' feature and create columns \n",
    "    df = pd.concat([df.drop(['value'], axis=1), df['value'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    # merge offer id and offer_id columns\n",
    "    df['offer id'] = df['offer id'].combine_first(df['offer_id'])\n",
    "    df = df.drop(columns = ['offer_id'])\n",
    "    \n",
    "    # split into three dataFrames and then merge rows with transaction and offer completed in the same time\n",
    "    df1 = df[df['event'] == 'offer completed'][['person' , 'event' , 'time' , 'offer id' , 'reward']]\n",
    "    df2 = df[df['event'] == 'transaction'][['person' ,  'time' , 'amount']]\n",
    "    df3 = df[df['event'] != 'offer completed']\n",
    "    df3 = df3[df3['event'] != 'transaction'][['person' , 'event' , 'time' , 'offer id']]         \n",
    "    # merge the two dataFrames on time\n",
    "    df_trans_completed = pd.merge(df1, df2, how='outer', on=['person', 'time'])\n",
    "    # merge with main dataFrames\n",
    "    df = pd.merge(df3, df_trans_completed, how='outer', on=['person', 'time' , 'event' , 'offer id'])\n",
    "    \n",
    "    # create columns of type of event with the value of time\n",
    "    df = pd.concat([df, df.pivot_table(values='time', index=df.index, columns='event', aggfunc='first')], axis=1, sort=False)\n",
    "    \n",
    "    # fill NaN values in the offer id feature as 'no offer' to keep track of the transactions without an offer\n",
    "    df['offer id'] = df['offer id'].fillna(value = 'no offer')\n",
    "    df = df.rename(columns={'person':'user id'})\n",
    "\n",
    "    # merge with offer_type dataframe\n",
    "    df = pd.merge(df, offer_df, how='outer', on=['offer id'])\n",
    "    df.rename(columns={'offer_type': 'offer type'} , inplace = True)    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_amount(df):\n",
    "\n",
    "    dict_values = {}\n",
    "    index_lst = []\n",
    "\n",
    "    a = df.loc[(df['event'] == 'offer received') & (df['offer type'] == 2)]\n",
    "\n",
    "    for i in range(a.shape[0]):   \n",
    "        b = df.loc[(df['time'] >= a['time'].values[i]) & (df['time'] <= (a['time'].values[i] + a['duration'].values[i])) & (df['offer id'] == 'no offer')]\n",
    "        if (b.shape[0] != 0):\n",
    "            index_lst.append(b.index[0])\n",
    "            c = b['amount'].to_list()[0]\n",
    "            dict_values.update({a.index.to_list()[i]: c})\n",
    "        else:\n",
    "            dict_values.update({a.index.to_list()[i]: np.nan})\n",
    "\n",
    "    df[\"amount\"].fillna(dict_values, inplace=True)\n",
    "    df.drop(index=index_lst, axis=0 , inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offer_merge(df):\n",
    "    \n",
    "    '''\n",
    "    For each user, map and select rows of a singular offer and merge them into one.\n",
    "    \n",
    "    IMPUT: df - (DataFrame) - modified transcription as default dataframe.\n",
    "    OUTPUT: df - (DataFrame) - rearange user data where each offer is in one row. \n",
    "    '''    \n",
    "    offers_received_lst = df['offer id'].unique().tolist()\n",
    "    total_offers_received = df['offer received'].count()\n",
    "    temp_df = df.head(0)\n",
    "    user_id = df['user id'].unique()[0]\n",
    "    \n",
    "    \n",
    "    for offer in offers_received_lst:\n",
    "        \n",
    "        #create data frame of an offer\n",
    "        offer_df = df[df['offer id'] == offer].copy()        \n",
    "        # check if the same offer has been receved more than one time if so, create flags to treat each offer independently.\n",
    "        if offer_df['offer received'].count() > 1:\n",
    "            cter = 0\n",
    "            flag = []\n",
    "                        \n",
    "            #create list to flag each offer            \n",
    "            for index, row in offer_df.iterrows():\n",
    "                if not np.isnan(row['offer received']):\n",
    "                    cter+=1\n",
    "                    flag.append(cter)                    \n",
    "                else:\n",
    "                    flag.append(cter)                    \n",
    "            offer_df['flag'] = flag \n",
    "            offer_df = offer_df.groupby(['flag' , 'offer id']).mean().reset_index().drop(columns='flag')\n",
    "\n",
    "        else:\n",
    "            offer_df = offer_df.groupby('offer id').mean().reset_index()\n",
    "            \n",
    "        temp_df = temp_df.append(offer_df , sort=False)\n",
    "    \n",
    "    temp_df = temp_df.reset_index()\n",
    "    temp_df = temp_df.drop(columns=['index'])\n",
    "    \n",
    "    df = temp_df\n",
    "    \n",
    "    return df , user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_completed_offers(df , user_id):\n",
    "    '''\n",
    "    For a given user, checks and drop transactions that were not influenced by an offer\n",
    "    \n",
    "    IMPUT: df - (DataFrame)\n",
    "    OUTPUT: df - (DataFrame) - rearange data \n",
    "    '''\n",
    "     \n",
    "    # fill NaN values with 0 for offers that were not completed\n",
    "    df[['reward' , 'amount']] = df[['reward' , 'amount']].fillna(value = 0)\n",
    "\n",
    "    # add column with the type of offer   \n",
    "    # df = pd.merge(df, map_offer_type, how='left', left_on=['offer id'] , right_on=['id'])\n",
    "    \n",
    "    # fill with offer type 4, for transactions that are not related with an offer\n",
    "    df['offer type'] = df['offer type'].fillna(value = 4)\n",
    "    df['user id'] = df['user id'].fillna(value = user_id)\n",
    "    \n",
    "    # check if an offer was completed before it was viewed or if it was not viewed, if so, drop it (the offer did not influenciate the transaction)\n",
    "    for row in range(len(df)):\n",
    "        if df.loc[row]['offer viewed'] > df.loc[row]['offer completed']:\n",
    "            df = df.drop([row])\n",
    "        elif np.isnan(df.loc[row]['offer viewed']) and not np.isnan(df.loc[row]['offer completed']):\n",
    "            df = df.drop([row])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(df):\n",
    "    '''\n",
    "    for each user rearange transactions influenced by an offer\n",
    "    and for each type of offer get:\n",
    "    transaction amount, number of offers recived, number of offers viewed and number of offers completed\n",
    "    note: it takes some time to process\n",
    "    \n",
    "    IMPUT: df - (dtaFrame)\n",
    "    OUTPUT:\n",
    "        amount_lst (lst) - list of dictionaries that contains amount spend and type of offer for each user\n",
    "        offers_lst (lst) - list of dictionaries that contains number of offers recived for each type\n",
    "        offers_view_lst (lst) - list of dictionaries that contains number of offers viewed for each type\n",
    "        offers_completed_lst (lst) - list of dictionaries that contains number of offers completed for each type\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    user_id_lst = profile['id'].tolist()\n",
    "    amount_lst = []\n",
    "    offers_lst = []\n",
    "    offers_view_lst = []\n",
    "    offers_completed_lst = []\n",
    "    \n",
    "    for user in user_id_lst:\n",
    "        \n",
    "        user_events = df[df['user id'] == user]\n",
    "        user_fill_amount = fill_amount(user_events)\n",
    "        user_events, user_id = offer_merge(user_fill_amount)\n",
    "        user_events = check_completed_offers (user_events , user_id)\n",
    "\n",
    "        amount = {'user id' : user}\n",
    "        offers = {'user id' : user}\n",
    "        offers_view = {'user id' : user}\n",
    "        offers_completed = {'user id' : user}\n",
    "\n",
    "        amount.update(user_events.groupby('offer type').mean()['amount'].to_dict())\n",
    "        offers.update(user_events.groupby('offer type').count()['offer id'].to_dict())\n",
    "        offers_view.update(user_events.groupby('offer type').count()['offer viewed'].to_dict())\n",
    "        offers_completed.update(user_events.groupby('offer type').count()['offer completed'].to_dict())\n",
    "\n",
    "        amount_lst.append(amount)\n",
    "        offers_lst.append(offers)\n",
    "        offers_view_lst.append(offers_view)\n",
    "        offers_completed_lst.append(offers_completed)\n",
    "        \n",
    "    return amount_lst , offers_lst , offers_view_lst , offers_completed_lst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_lst (lst):\n",
    "    '''\n",
    "    create dataframe from a list of dictionaries\n",
    "    IMPUT: lst (list)\n",
    "    OUTPUT: DF (dataFrame)\n",
    "     '''\n",
    "    \n",
    "    df = pd.DataFrame(lst).drop(columns=4)\n",
    "    df.fillna(value = 0 , inplace = True)\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split gender into dummies columns\n",
    "profile_mod = pd.concat([profile , pd.get_dummies(profile['gender'])],axis=1)\n",
    "profile_mod.drop(['gender' , 'became_member_on'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map offer type \n",
    "map_offer_type, dict_offer_type = offer_type_mapper(portfolio)\n",
    "#transform days\n",
    "map_offer_type['duration'] = map_offer_type['duration'] * 24\n",
    "map_offer_type.rename(columns={'id': 'offer id'} , inplace = True)\n",
    "\n",
    "map_offer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange transcript df\n",
    "arrange_transcript = arrange_events(transcript , map_offer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: this will take some time to execute, you can grab a coffee ;)\n",
    "amount_lst , offers_lst , offers_view_lst , offers_completed_lst = get_events(arrange_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount data\n",
    "amount_type = pd.DataFrame(amount_lst)\n",
    "amount_type.rename(columns={1: 'type 1', 2: 'type 2', 3: 'type 3' , 4: 'type 4'} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_offers = df_from_lst (offers_lst)\n",
    "offers_viewed = df_from_lst (offers_view_lst)\n",
    "offers_completed = df_from_lst (offers_completed_lst)\n",
    "\n",
    "user_offers.rename(columns={1: 'offers type 1', 2: 'offers type 2', 3: 'offers type 3'} , inplace = True)\n",
    "offers_viewed.rename(columns={1: 'viewed type 1', 2: 'viewed type 2', 3: 'viewed type 3'} , inplace = True)\n",
    "offers_completed.rename(columns={1: 'completed type 1', 2: 'completed type 2', 3: 'completed type 3'} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data frames\n",
    "amount_offer = pd.merge(amount_type, user_offers, how='inner' , on=\"user id\")\n",
    "amount_offer = pd.merge(amount_offer, offers_viewed, how='inner' , on=\"user id\")\n",
    "amount_offer = pd.merge(amount_offer, offers_completed, how='inner' , on=\"user id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into 3 datasets\n",
    "amount_type_1 = amount_offer[['user id' , 'type 1' , 'offers type 1' , 'viewed type 1' , 'completed type 1']].copy() # 'dif 1'\n",
    "amount_type_2 = amount_offer[['user id' , 'type 2' , 'offers type 2' , 'viewed type 2' , 'completed type 2']].copy()\n",
    "amount_type_3 = amount_offer[['user id' , 'type 3' , 'offers type 3' , 'viewed type 3' , 'completed type 3']].copy()\n",
    "amount_type_4 = amount_offer[['user id' , 'type 4']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_type_1 = pd.merge(profile_mod, amount_type_1, how='inner' , left_on=\"id\" , right_on=\"user id\")\n",
    "amount_type_1.drop(['id'],axis=1, inplace=True)\n",
    "\n",
    "amount_type_2 = pd.merge(profile_mod, amount_type_2, how='inner' , left_on=\"id\" , right_on=\"user id\")\n",
    "amount_type_2.drop(['id'],axis=1, inplace=True)\n",
    "\n",
    "amount_type_3 = pd.merge(profile_mod, amount_type_3, how='inner' , left_on=\"id\" , right_on=\"user id\")\n",
    "amount_type_3.drop(['id'],axis=1, inplace=True)\n",
    "\n",
    "amount_type_4 = pd.merge(profile_mod, amount_type_4, how='inner' , left_on=\"id\" , right_on=\"user id\")\n",
    "amount_type_4.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear NaN for each data Set, users that did not recive that type of offer\n",
    "amount_type_1.dropna(axis=0 , inplace=True)\n",
    "amount_type_1.drop(amount_type_1[amount_type_1['viewed type 1'] == 0].index , inplace=True)\n",
    "\n",
    "amount_type_2.dropna(axis=0 , inplace=True)\n",
    "amount_type_2.drop(amount_type_2[amount_type_2['viewed type 2'] == 0].index , inplace=True)\n",
    "\n",
    "amount_type_3.dropna(axis=0 , inplace=True)\n",
    "amount_type_3.drop(amount_type_3[amount_type_3['viewed type 3'] == 0].index , inplace=True)\n",
    "\n",
    "amount_type_4.dropna(axis=0 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataFrames to CSV files\n",
    "amount_type_1.to_csv('data/amount_type_1.csv' , index=False)\n",
    "amount_type_2.to_csv('data/amount_type_2.csv' , index=False)\n",
    "amount_type_3.to_csv('data/amount_type_3.csv' , index=False)\n",
    "amount_type_4.to_csv('data/amount_type_4.csv' , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv')",
   "language": "python",
   "name": "python37764bitvenvf7323f51036b43e7a745900362034ad3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}